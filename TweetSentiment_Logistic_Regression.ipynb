{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TweetSentiment-Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNiR8FAlzBaBLhnGELRB15z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7wikd/Logistic_Regression--Sentiment_Analysis/blob/master/TweetSentiment_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFvksne6Ouzq"
      },
      "source": [
        "## Logistic Regression for Sentiment Analysis\n",
        "\n",
        "Using the dataset of tweets\n",
        "\n",
        "Twitter HOWTO: https://www.nltk.org/howto/twitter.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUj06TpmPWX_"
      },
      "source": [
        "### Importing NLTK Library\n",
        "\n",
        "\n",
        "* twitter_samples: if you're running this notebook on your local computer, you will need to download it using:\n",
        "```Python\n",
        "nltk.download('twitter_samples')\n",
        "```\n",
        "\n",
        "* stopwords: if you're running this notebook on your local computer, you will need to download it using:\n",
        "```python\n",
        "nltk.download('stopwords')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QerV3VVaOiLS",
        "outputId": "59059fd5-cca8-4d1f-b360-a73618a98ba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAozqX98PgAf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmRS5Rmjkh7o"
      },
      "source": [
        "### Creating functions for Processing and Frequency Calculation\n",
        "\n",
        "#### Process (`process()`)\n",
        "* Clean the text\n",
        "* Tokenize into separate words\n",
        "* Remove Stopwords\n",
        "* Convert words to stems\n",
        "\n",
        "#### Frequency (`frequency()`)\n",
        "* Counts the occurences of a word in the 'corpus'\n",
        "* Assigns label '1' for positive tweet\n",
        "* Assigns label '0' for negative tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNdJvvYQVnd"
      },
      "source": [
        "#<----------- Libraries ----------->\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "#<----------- Processing ----------->\n",
        "\n",
        "def process(tweet):\n",
        "  stemmer = PorterStemmer()\n",
        "  stopwords_en = stopwords.words('english')\n",
        "  tweet = re.sub(r'\\$\\w*','',tweet)\n",
        "  tweet = re.sub(r'^RT[\\s]+','',tweet)\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*','',tweet)\n",
        "  tweet = re.sub(r'#','',tweet)\n",
        "\n",
        "  tokenizer = TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
        "  tokenize = tokenizer.tokenize(tweet)\n",
        "\n",
        "  tweet_clean = []\n",
        "  for word in tokenize:\n",
        "    if(word not in stopwords_en and word not in string.punctuation):\n",
        "      stem_word = stemmer.stem(word)\n",
        "      tweet_clean.append(stem_word)\n",
        "  return tweet_clean\n",
        "\n",
        "#<----------- Frequency----------->\n",
        "\n",
        "def frequency(tweets,labels):\n",
        "  labels = np.squeeze(labels).tolist()\n",
        "\n",
        "  freqs = {}\n",
        "\n",
        "  for label, tweet in zip(labels,tweets):\n",
        "    for word in process(tweet):\n",
        "      pair = (word,label)\n",
        "      if pair in freqs:\n",
        "        freqs[pair] += 1\n",
        "      else:\n",
        "        freqs[pair] = 1\n",
        "  return freqs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fU7STcJQQMs"
      },
      "source": [
        "### Positive and Negative Tweets separated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALVPGUSQQkon"
      },
      "source": [
        "positive_all = twitter_samples.strings('positive_tweets.json')\n",
        "negative_all = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkT9hjuVTAzP"
      },
      "source": [
        "#<----------- Splitting data ----------->\n",
        "train_split = 0.8\n",
        "\n",
        "#80% training, 20% testing\n",
        "\n",
        "Pos_train = positive_all[:int(len(positive_all)*train_split)]\n",
        "Neg_train = negative_all[:int(len(negative_all)*train_split)]\n",
        "Pos_test = positive_all[int(len(positive_all)*train_split):]\n",
        "Neg_test = negative_all[int(len(positive_all)*train_split):]\n",
        "\n",
        "train_X = Pos_train + Neg_train\n",
        "test_X = Pos_test + Neg_test\n",
        "\n",
        "train_Y = np.append(np.ones((len(Pos_train),1)),np.zeros((len(Neg_train),1)),axis = 0)\n",
        "test_Y = np.append(np.ones((len(Pos_test),1)),np.zeros((len(Neg_test),1)),axis = 0)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7hnjOReTy9V",
        "outputId": "615c7a00-dcec-4089-be33-1b837f10accc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"train_Y.shape = \"+str(train_Y.shape))\n",
        "print(\"test_Y.shape = \"+str(test_Y.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_Y.shape = (8000, 1)\n",
            "test_Y.shape = (2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfwQujOvUxDE",
        "outputId": "92d14dac-dc6b-4dfe-dc0b-e784c1d2cca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "freqs = frequency(train_X,train_Y)\n",
        "\n",
        "print('This is an example of a positive tweet: \\n', train_X[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process(train_X[0]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is an example of a positive tweet: \n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppw9ns8kVut-"
      },
      "source": [
        "### Sigmoid Function\n",
        "\n",
        "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
        "\n",
        "Regression:\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "Note that the $\\theta$ values are \"weights\".\n",
        "\n",
        "Logistic regression\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
        "\n",
        "where, $$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "and 'z' are known as logits\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I_mf4gFVWDy",
        "outputId": "202ffd63-91c8-4c18-eeaf-0b27b65a15eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def sigmoid(z):\n",
        "  h = 1.0/(1.0+np.exp(-z))\n",
        "  return h\n",
        "\n",
        "\n",
        "#testing sigmoid function:\n",
        "\n",
        "if(sigmoid(0)== 0.5):\n",
        "  print(\"Hello! Correct\")\n",
        "print(sigmoid(1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello! Correct\n",
            "0.7310585786300049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na7h0vCGiSs8"
      },
      "source": [
        "### Gradient Descent\n",
        "\n",
        "#### Cost Function\n",
        "\n",
        "Cost function in Logistic Regression: The average of log losses across all training examples.\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))$$\n",
        "* $m$ is the number of training examples\n",
        "* $y^{(i)}$ is the actual label of the i-th training example.\n",
        "* $h(z(\\theta)^{(i)})$ is the model's prediction for the i-th training example.\n",
        "\n",
        "The loss function for a single training example is\n",
        "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
        "\n",
        "* All the $h$ values are between 0 and 1, so the logs will be negative. That is the reason for the factor of -1 applied to the sum of the two loss terms.\n",
        "* Note that when the model predicts 1 ($h(z(\\theta)) = 1$) and the label $y$ is also 1, the loss for that training example is 0. \n",
        "* Similarly, when the model predicts 0 ($h(z(\\theta)) = 0$) and the actual label is also 0, the loss for that training example is 0. \n",
        "* However, when the model prediction is close to 1 ($h(z(\\theta)) = 0.9999$) and the label is 0, the second term of the log loss becomes a large negative number, which is then multiplied by the overall factor of -1 to convert it to a positive loss value. The closer the model prediction gets to 1, the larger the loss.\n",
        "\n",
        "#### Update the weights\n",
        "\n",
        "To update your weight vector $\\theta$, gradient descent is iteratively applied improve model's predictions.  \n",
        "The gradient of the cost function $J$ with respect to one of the weights $\\theta_j$ is:\n",
        "\n",
        "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j$$\n",
        "* 'i' is the index across all 'm' training examples.\n",
        "* 'j' is the index of the weight $\\theta_j$, so $x_j$ is the feature associated with weight $\\theta_j$\n",
        "\n",
        "* To update the weight $\\theta_j$, we adjust it by subtracting a fraction of the gradient determined by $\\alpha$:\n",
        "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
        "* The learning rate $\\alpha$ is a value that we choose to control how big a single update will be.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ3FxXzeWL8k"
      },
      "source": [
        "def gradient_descent(x,y,theta,alpha, num_iters):\n",
        "  m = x.shape[0]\n",
        "\n",
        "  for i in range(0,num_iters):\n",
        "    z = np.dot(x,theta)\n",
        "\n",
        "    h = sigmoid(z)\n",
        "\n",
        "    J = ((-1/m)*(np.dot(y.T, np.log(h))+np.dot((1-y).T,np.log(1-h))))\n",
        "  \n",
        "    theta = theta - (alpha/m)*np.dot((x.T),(h-y))\n",
        "\n",
        "  J = float(J)\n",
        "  return J, theta"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC7vgCSzkTGR"
      },
      "source": [
        "### Extracting Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpnfqrhrXs1v"
      },
      "source": [
        "def features_extract(tweet,freqs):\n",
        "  word_l = process(tweet)\n",
        "\n",
        "  x = np.zeros((1,3))\n",
        "  x[0,0] = 1\n",
        "\n",
        "  for word in word_l:\n",
        "    x[0,1] += freqs.get((word,1.0),0)\n",
        "    x[0,2] += freqs.get((word,0.0),0)\n",
        "\n",
        "  assert(x.shape == (1,3))\n",
        "  return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7_SlK6Ja_hw"
      },
      "source": [
        "### TRAINING THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGM-xfIFbCfZ",
        "outputId": "279fc3b6-78fd-43fc-cb97-6df6c82c2b52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = np.zeros((len(train_X),3))\n",
        "\n",
        "for i in range(len(train_X)):\n",
        "  X[i,:] = features_extract(train_X[i],freqs)\n",
        "\n",
        "Y = train_Y\n",
        "\n",
        "J, theta = gradient_descent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost post-training: {J:.8f}.\")\n",
        "print(f\"Vector of weights: {[round(t,8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cost post-training: 0.24216529.\n",
            "Vector of weights: [7e-08, 0.0005239, -0.00055517]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0R1Q0oXbDni"
      },
      "source": [
        "### TESTING THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea91vpK5aENj"
      },
      "source": [
        "def predict(tweet,freqs,theta):\n",
        "  x = features_extract(tweet,freqs)\n",
        "\n",
        "  y_pred = sigmoid(np.dot(x,theta))\n",
        "\n",
        "  return y_pred"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmR-6RAtmwpU",
        "outputId": "709c0f51-0582-4083-ecf1-6cf580dbfe24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict(tweet, freqs, theta)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am happy -> 0.518580\n",
            "I am bad -> 0.494339\n",
            "this movie should have been great. -> 0.515331\n",
            "great -> 0.515464\n",
            "great great -> 0.530898\n",
            "great great great -> 0.546273\n",
            "great great great great -> 0.561561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3trHS_rKm5DZ"
      },
      "source": [
        "### Checking the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b25qzLl5mxc_"
      },
      "source": [
        "def Accuracy(test_X,test_Y,freqs,theta):\n",
        "  y_hat = []\n",
        "\n",
        "  for tweet in test_X:\n",
        "    y_pred = predict(tweet,freqs,theta)\n",
        "    \n",
        "    if y_pred > 0.5:\n",
        "      y_hat.append(1)\n",
        "    elif y_pred < 0.5:\n",
        "      y_hat.append(0)\n",
        "\n",
        "  accuracy = (np.asarray(y_hat) == np.squeeze(test_Y)).sum()/len(test_X)\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuTaDRH1nkd_",
        "outputId": "5d1b0eb2-eeae-40ae-d916-ddb9da521bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy = Accuracy(test_X,test_Y,freqs,theta)\n",
        "print(f\"Model Accuracy = {accuracy:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy = 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPMYQMnxRQL8"
      },
      "source": [
        "Accuracy = 99.50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63vM1-vqQ5h3"
      },
      "source": [
        "### Test against custom data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7739uMgnxv2",
        "outputId": "2a757e4f-8f08-4b8f-bbaf-d5a1428e5c3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Feel free to change the tweet below\n",
        "#[A random sentence here]\n",
        "my_tweet = 'Hello World! Nice to meet you!'\n",
        "print(process(my_tweet))\n",
        "y_hat = predict(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else: \n",
        "    print('Negative sentiment')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', 'world', 'nice', 'meet']\n",
            "[[0.51339539]]\n",
            "Positive sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzBwZWaZRa9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}